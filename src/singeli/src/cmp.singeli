include './base'
include './cbqnDefs'
include './f64'
include './bitops'
def arch_defvw{if hasarch{'AVX512BW'}} = 512

def fillbits{dst:(*u64), len:(ux), v   } = { emit{void, 'fillBits',    dst, len, v   }; return{}; }
def fillbits{dst:(*u64), len:(ux), v, x} = { emit{void, 'fillBitsDec', dst, len, v, x}; return{}; }
def cmp_err{x} = { emit{void, 'cmp_err'}; return{}; }

fn cmpIX(dst:(*u64), len:ux, x:(u64), v:(u1)) : void = {
  nan:u1 = q_f64{x}
  if (~(nan | q_chr{x})) cmp_err{x}
  fillbits{dst, len, v&~nan, x}
}

def eqne{op} = same{op,__eq} or same{op,__ne}

def pathAS{dst, len, T, op, x if issigned{T}} = {
  def R{f if eqne{op}} = {
    if (rare{__floor{f}!=f}) fillbits{dst, len, op{0,1}, x} # also includes check for NaN/sNaN
    ftrunc{i64,f}
  }
  def R{f if same{op,__lt} or same{op,__ge}} = ftrunc{i64,__ceil{f}}
  def R{f if same{op,__gt} or same{op,__le}} = ftrunc{i64,__floor{f}}
  
  xf:f64 = interp_f64{x}
  xi64:i64 = R{xf}
  xT:T = trunc{T, xi64}
  def nanchk{} = {
    if(~eqne{op}) { # NaN was already checked for â‰ /=
      if (isNaN{xf}) { call{cmpIX, dst, len, x, op{0,1}}; return{}; }
    }
  }
  if (not hasarch{'X86_64'}) nanchk{}
  if (rare{promote{i64, xT}!=xi64}) {
    if (hasarch{'X86_64'}) nanchk{}
    fillbits{dst, len, op{0,xf}}
  }
  xT
}

def pathAS{dst, len, T==f64, op, x} = {
  if (rare{~q_f64{x}}) {
    if (not eqne{op} and ~q_chr{x}) cmp_err{x}
    fillbits{dst, len, op{0,1}, x}
  }
  from_B{T,x}
}

def pathAS{dst, len, T, op, x if isunsigned{T}} = {
  if (rare{~q_chr{x}}) {
    if (not eqne{op} and ~q_f64{x}) cmp_err{x}
    fillbits{dst, len, op{1,0}, x}
  }
  xc32:u32 = from_B{u32,x}
  if (xc32 > maxvalue{T}) fillbits{dst, len, op{0,1}}
  trunc{T, xc32}
}



def any2bit{VT=[k]T, unr, op0, wS, wV, xS, xV, dst:(*u64), len:(ux)} = {
  def bulk = k*unr
  xi:ux = 0
  
  def op = match (op0) {
    {_ if not hasarch{'X86_64'} or hasarch{'AVX512F'}} => op0
    {(__le) if issigned{T}} => __gt
    {(__ge) if issigned{T}} => __lt
    {(__lt) if isunsigned{T}} => __ge
    {(__gt) if isunsigned{T}} => __le
    {(__ne) if isint{T}} => __eq
    {_} => op0
  }
  def mask = if (same{op0, op}) hom_to_int else ({x} => ~hom_to_int{x})
  
  @for_nz (ri to cdiv{len,bulk}) {
    store_bits{bulk, dst, ri, mask{each{{j}=>op{wV{xi+j}, xV{xi+j}}, iota{unr}}}}
    xi+= unr
  }
}
fn aa2bit{VT=[_]T, unr, op}(dst:*u64, wr:*void, xr:*void, len:ux) : void = {
  wv:= *VT~~wr; ws:= *T~~wr
  xv:= *VT~~xr; xs:= *T~~xr
  any2bit{VT, unr, op, load{ws,.}, load{wv,.}, load{xs,.}, load{xv,.}, dst, len}
}

fn as2bit{VT=[_]T, unr, op}(dst:*u64, wr:*void, x:u64, len:ux) : void = {
  wv:= *VT~~wr; ws:= *T~~wr
  xv:= VT**pathAS{dst, len, T, op, x}
  any2bit{VT, unr, op, load{ws,.}, load{wv,.}, {i}=>x, {i}=>xv, dst, len}
}

fn bitAA{bitop}(dst:*u64, wr:*void, xr:*void, len:ux) : void = {
  @for_nz (dst, w in *u64~~wr, x in *u64~~xr over cdiv{len,64}) dst = bitop{w,x}
}

fn bit_not(dst:*u64, x:*u64, len:ux) : void = { am:=cdiv{len,64}; emit{void, 'bit_negatePtr', dst, x, am} }
fn bit_cpy(dst:*u64, x:*u64, len:ux) : void = { am:=cdiv{len,64}; emit{void, 'memcpy', dst, x, am*8} }

fn bitAS{op}(dst:*u64, wr:*void, x:u64, len:ux) : void = { # show{'bitAS'}
  xf:f64 = interp_f64{x}
  r0:u1 = op{0,xf}
  r1:u1 = op{1,xf}
  if (r0==r1) {
    if (rare{isNaN{xf}}) {
      if (eqne{op}) fillbits{dst, len, r0, x}
      else { call{cmpIX, dst, len, x, op{0,1}}; return{}; }
    }
    fillbits{dst, len, r0}
    return{}
  }
  if (r0) call{bit_not, dst, *u64~~wr, len}
  else    call{bit_cpy, dst, *u64~~wr, len}
}

def table{aa, F, w, G_bit, G_vec} = {
  tup{
    G_bit{},
    ...each{{E}=>{
      def E2 = (if (aa and isunsigned{E} and (eqne{F} or E==u32)) {ty_s{E}} else E)
      def bulk = w/width{E2}
      def unr = if (hasarch{'X86_64'} and width{E2}==16) 2 else __max{8/bulk,1}
      G_vec{[bulk]E2, __max{tern{hasarch{'AARCH64'},2,1}, unr}}
    }, tup{i8, i16, i32, f64, u8, u16, u32}}
  }
}
def tableAA{w, F, F_bit} = table{1, F, w, {} => bitAA{F_bit}, {V, u} => aa2bit{V, u, F}}
def tableAS{w, F       } = table{0, F, w, {} => bitAS{F},     {V, u} => as2bit{V, u, F}}


export_tab{'simd_eqAS', tableAS{arch_defvw{}, __eq}}; export_tab{'simd_eqAA', tableAA{arch_defvw{}, __eq, {a,b}=>a ^ ~b}}
export_tab{'simd_neAS', tableAS{arch_defvw{}, __ne}}; export_tab{'simd_neAA', tableAA{arch_defvw{}, __ne, {a,b}=>a ^  b}}
export_tab{'simd_gtAS', tableAS{arch_defvw{}, __gt}}; export_tab{'simd_gtAA', tableAA{arch_defvw{}, __gt, {a,b}=>a & ~b}}
export_tab{'simd_geAS', tableAS{arch_defvw{}, __ge}}; export_tab{'simd_geAA', tableAA{arch_defvw{}, __ge, {a,b}=>a | ~b}}
export_tab{'simd_ltAS', tableAS{arch_defvw{}, __lt}}
export_tab{'simd_leAS', tableAS{arch_defvw{}, __le}}
