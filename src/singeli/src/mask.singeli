local def maskInit1{w} = {
  apply{merge, each{{x} => {
    merge{(w/8-1)**255, (1<<x)-1, (w/8)**0}
  }, iota{8}}}
}
mask256_1:*u8 = maskInit1{256}; def maskOfBit{T,n & width{T}==256} = load{*[32]u8  ~~  (mask256_1 + (n>>3)^31 + 64*(n&7))}
mask128_1:*u8 = maskInit1{128}; def maskOfBit{T,n & width{T}==128} = load{*[16]u8  ~~  (mask128_1 + (n>>3)^15 + 32*(n&7))}

mask256:*i64 = merge{4 ** -1,  4 ** 0}
local def maskOfImpl{T, n, w} = load{*ty_u{T} ~~ (*u8~~mask256 + 32 - n*(elwidth{T}/8))}

# get mask of first n items; 0 ≤ n ≤ vcount{T}
def maskOf{T,n & width{T}==256} = maskOfImpl{T, n, 256}
def maskOf{T,n & width{T}==128} = maskOfImpl{T, n, 128}

def anyne{x:T, y:T, M & M{0}==0 & isvec{T}} = ~homAll{x==y}
def anyne{x:T, y:T, M & M{0}==1 & isvec{T}} =  homAny{M{x!=y}}
def anyne{x:T, y:T, M & M{0}==0 & anyInt{x}} = x!=y
def anyne{x:T, y:T, M & M{0}==1 & anyInt{x}} = M{x^y} != 0
def anyneBit{x:T, y:T, M} = ~M{x^y, 'all bits zeroes'}

def anynePositive{x:T, y:T, M & M{0}==0} = anyne{x, y, M}
def anynePositive{x:T, y:T, M & M{0}==1 & isvec{T}                      } = (promote{u32,~homMask{         x==y }} << (32-M{'count'}  )) != 0
def anynePositive{x:T, y:T, M & M{0}==1 & width{T}==256 & elwidth{T}==16} = (promote{u32,~homMask{[32]u8~~(x==y)}} << (32-M{'count'}*2)) != 0

def maskNone{x} = x
def maskNone{x, mode=='all bits zeroes'} = andAllZero{x, x}
def maskAfter{n} = {
  def mask{x:X & isvec{X}} = x & (X~~maskOf{X,n})
  def mask{x:X & anyInt{x}} = x & ((1<<n) - 1)
  def mask{x:X, mode=='all bits zeroes'} = andAllZero{x, X~~maskOfBit{X,n}}
  def mask{X, mode=='to sign bits'} = maskOf{X,n}
  def mask{mode=='count'} = n
  def mask{x & istup{x} & tuplen{x}==1} = tup{mask{tupsel{0,x}}}
  def mask{x==0} = 1
}



def loadLowBatch{T, ptr:P, w, n & eltype{P}==eltype{T}} = loadLow{*T ~~ (ptr + n*(w/elwidth{P})), w}

# store vcount{T} items into the n'th batch of ptr elements, compressing the items if needed; masked by M
def storeBatch{ptr:P, n, x:T, M} = {
  def rpos = ptr + n*vcount{T}
  def E0 = eltype{P}
  def TF = to_el{E0, T}
  xu:= narrow{E0, x}
  
  if (M{0}) maskstoreF{*TF~~rpos, M{TF, 'to sign bits'}, undefPromote{TF, xu}}
  else storeLow{rpos, vcount{T}*width{E0}, xu}
}

# (sign/zero)-extend n'th batch of vcount{T} elements of P into elements of T
def loadBatch{ptr:P, n, T} = {
  def rpos = ptr + n*vcount{T}
  def E0 = eltype{P}
  
  widen{T, loadLow{*to_el{E0, T} ~~ rpos, vcount{T}*width{E0}}}
}

def loadBatch {ptr:P, ns, T     & istup{ns}} = each{{n  } => loadBatch {ptr, n, T   }, ns}
def storeBatch{ptr:P, ns, xs, M & istup{ns}} = each{{n,x} => storeBatch{ptr, n, x, M}, ns, xs}



def maskedLoop{bulk, l, step} = maskedLoop{bulk, 0, l, step}

def maskedLoop{bulk, i0, l, step} = {
  m:u64 = l/bulk
  @for (i from i0 to m) step{i, maskNone}
  
  left:= l & (bulk-1)
  if (left!=0) step{m, maskAfter{left}}
}

def maskedLoopPositive{bulk, l:L, step} = {
  i:L = 0
  while(i < (l-1)/bulk) {
    step{i, maskNone}
    ++i
  }
  step{i, maskAfter{l - i*bulk}}
}

# masked unrolled loop
#  bulk: vector count
#  unr: unroll amount
#  l: length
#  step: {is, M}=>operation
#    'is' is a tuple of bulk indexes to process, usable as an arg to loadBatch/storeBatch to get a tuple of vectors
#  fromunr (optional): {}=>{transition from unrolled to non-unrolled}
def muLoop{bulk, unr, l, step, fromunr} = {
  if (unr==1) {
    maskedLoop{bulk, l, {i, M} => step{tup{i}, M}}
  } else {
    m:u64 = l/bulk
    if (m > 0) {
      i:u64 = 0
      if (unr <= m) {
        while ((i+unr) <= m) {
          def is = each{{j}=>i+j, iota{unr}}
          step{each{{j}=>i+j, iota{unr}}, maskNone}
          i+= unr
        }
        fromunr{}
      }
      if (unr==2) {
        if (i!=m) step{tup{i}, maskNone}
      } else {
        @for(j from i to m) step{tup{j}, maskNone}
      }
    }
    
    left:= l & (bulk-1)
    if (left!=0) step{tup{m}, maskAfter{left}}
  }
}
def muLoop{bulk, unr, l, step} = muLoop{bulk, unr, l, step, {}=>0}
