# accumulator operations:
#   acc{'flush'} - flush vector accumulator (both unrolled and non-unrolled)
#   acc{'flush_min'} - how many 'acc' calls can be done between flushes for worst-case arguments
#   acc{'acc', val} - add value(s) to the accumulator
#   acc{'acc', M, val} - add value(s) to the accumulator based on the mask
#   acc{'from_unr'} - must be invoked when transitioning from accumulating â‰¥2-elt tuples (1-elt tuples / plain vectors are fine any time before 'to_scal')
#   acc{'to_scal'} - must be called when transitioning from vectors to scalar accumulates or taking 'scal_result'
#   acc{'to_scal', n} - expanded 'to_scal', required for some ops; n must be the number of elements accumulated
#   acc{'scal_result'} - get result of scalar accumulates
#   acc{'vec_result'} - get result of vector accumulates (i.e. 'to_scal' + 'scal_result')
#   acc{'vec_result', n} - 'vec_result', passing n to 'to_scal'



# general things
local def extend finish{me} = {
  def me{'vec_result', ...rest} = {
    me{'to_scal', ...rest}
    me{'scal_result'}
  }
}
local def int_els{DE, SE} = isint{DE} and isint{SE} and quality{DE}==quality{SE} and DE>=SE
def mu_extra{...args} = {
  def get_all{prop} = each{{c}=>c{prop}, args}
  tup{
    {} => get_all{'from_unr'},
    fold{__min, get_all{'flush_min'}},
    {} => get_all{'flush'},
  }
}



# scalar accumulators
local def scalar_acc_impl{F, T, ident} = {
  acc:T = ident
  def me{'acc', v} = {
    acc = F{acc, v}
  }
  def me{'vec_result'} = me{'scal_result'}
  def me{'scal_result'} = acc
}
local def scal_bool{T} = is{T,'!'} or isunsigned{T}

local def add_promote{a:A,b} = a + promote{A, b}
def assoc_accumulator{F,  '!', T if primt{T}, ident} = scalar_acc_impl{F, T, ident}
def count_accumulator{DE, '!', T if scal_bool{T} and isunsigned{DE}} = scalar_acc_impl{add_promote, DE, 0}
def bool_accumulator {F,  '!', T if scal_bool{T}, ident} = scalar_acc_impl{F, u1, ident}
def sum_accumulator  {DE, '!', T if primt{T}} = scalar_acc_impl{add_promote, DE, 0}



# vector accumulators
local def mask_ident{A, ident}{M, acc_vec, v:V=[_]_} = {
  if (M{0}==0) A{acc_vec, v}
  else if (is{ident,0}) A{acc_vec, M{v}}
  else blend_hom{acc_vec, A{acc_vec, v}, M}
}

local def acc_impl{A, M, unr, VT, S, init} = acc_impl{A, M, unr, VT, init, S, init}
local def acc_impl{A if kgen{A}, M if kgen{M}, unr if knum{unr}, VT=[k]E, vinit0, S, sinit} = {
  acc_scal:S = sinit
  def vinit = VT**vinit0
  def acc_tup = @collect(unr) { acc_var:=vinit }
  def acc_vec = select{acc_tup, 0} # shared with acc_tup to allow single-vector accumulates before from_unr
  
  def me{'acc', v} = {
    match (v) {
      {_:[_]_} => acc_vec = A{mask_none, acc_vec, v}
      {{v0:_}} => acc_vec = A{mask_none, acc_vec, v0}
      {{..._}} => each{{a,c} => a = A{mask_none, a,c}, acc_tup, v}
      {_:T if primt{T}} => acc_scal = A{mask_none, acc_scal, v}
    }
  }
  def me{'acc', M if kgen{M}, v} = {
    match (v) {
      {{v0}} => me{'acc', M, v0}
      {_      if M{0}==0} => me{'acc', v}
      {_:[_]_ if M{0}==1} => acc_vec = A{M, acc_vec, v}
    }
  }
  def me{'from_unr'} = {
    acc_vec = tree_fold{M, acc_tup}
  }
  def me{'to_scal', ..._} = {
    acc_scal = vfold{M, acc_vec}
  }
  def me{'flush_min'} = 1/0
  def me{'flush'} = {}
  def me{'scal_result'} = acc_scal
  tup{me, acc_scal, acc_tup, acc_vec}
}
def assoc_accumulator{F if kgen{F}, unr if knum{unr}, VT=[_]E, ident} = {
  def {me, ..._} = acc_impl{mask_ident{F, ident}, F, unr, VT, E, ident}
  extend finish{me}
  me
}

def bool_accumulator{F, unr, VT=[k]SE, ident if isunsigned{SE}} = {
  def {acc, acc_scal, acc_tup, acc_vec} = acc_impl{mask_ident{F,ident}, F, unr, VT, ident * hom_ones{SE}, u1, ident}
  def me{...} = acc
  def me{'acc', ...M, v} = acc{'acc', ...M, assert_hom{v}}
  def me{'to_scal', ..._} = match (F) {
    {(|)} => acc_scal|= any_hom{acc_vec}
    {(&)} => acc_scal&= all_hom{acc_vec}
  }
  def me{'scal_result'} = cast_i{u1, acc{'scal_result'}}
  extend finish{me}
}



# aarch64-specific accumulators
def sum_accumulator{DE, unr, VT=[_]SE if int_els{DE,SE} and DE>SE and hasarch{'AARCH64'}} = {
  def A = if (width{DE}>width{ux}) DE else primtype{quality{DE}, width{ux}}
  def VM = el_m{VT}
  def [_]ME = VM
  def exact = DE == ME
  def addpwa{a:(A), x:E if primt{E}} = a + promote{A,x}
  def {acc, acc_scal, acc_tup, acc_vec} = acc_impl{mask_ident{addpwa,0}, +, unr, VM, A, 0}
  
  def me{...} = acc
  def into_scal{vs} = {
    def ps = each{fold_addw{DE,.}, vs}
    acc_scal+= tree_fold{+, each{promote{A,.}, ps}}
  }
  def me{'from_unr'} = into_scal{slice{acc_tup, 1}}
  def me{'to_scal', ..._} = into_scal{tup{acc_vec}}
  def me{'flush_min'} = if (exact) {
    1/0
  } else {
    def p{G} = __floor{G{ME} / G{SE} / 2} # divided by 2 because addpwa adds two elements per iter
    if (issigned{SE}) __min{p{maxvalue}, p{minvalue}} else p{maxvalue}
  }
  def me{'flush'} = if (not exact) {
    into_scal{acc_tup}
    acc_tup = VM**0
  }
  def me{'scal_result'} = cast_i{DE, acc_scal}
  extend finish{me}
}



# x86_64-specific accumulators; TODO: AVX-512 could use dpbusd/dpwssd, though with the higher latency that should be behind a high unroll amount
def sum_accumulator{DE, unr, VT=[k]SE if int_els{DE,SE} and width{SE}==8 and hasarch{'X86_64'}} = {
  def VM = [k/8]u64
  def VU = [k]u8
  def adda{M, a:(VM), c:(VT)} = {
    def cu = if (SE==i8) ty_u{c} ^ VU**128 else c
    a + absdiff_sum{8, M{cu}, VU**0}
  }
  def {acc, acc_scal, acc_tup, acc_vec} = acc_impl{adda, +, unr, VM, DE, 0}
  def me{...} = acc
  def me{'to_scal', ...rest} = {
    acc_scal+= cast_i{DE, match (SE, ...rest) {
      {(u8),..._} => vfold{+, acc_vec}
      {(i8),   n} => vfold{+, acc_vec} - cast_i{u64, n}*128
    }}
  }
  extend finish{me}
}

def sum_accumulator{DE, unr, VT=[k]SE if int_els{DE,SE} and SE==i16 and DE==i32 and hasarch{'X86_64'}} = { # TODO could probably extend to u16? and to 64-bit DE via flush
  def VM = [k/2]i32
  def adda{M, a:(VM), c:(VT)} = {
    if (M{0}) a - mul_sum{2, c, VT~~M{VT, 'to homogeneous bits'}}
    else a + mul_sum{2, c, VT**1}
  }
  def {acc, acc_scal, acc_tup, acc_vec} = acc_impl{adda, +, unr, VM, DE, 0}
  def me{...} = acc
  extend finish{me}
}

local include 'util/perv'
def sum_accumulator{DE==i64, unr, VT=[k]SE==i32 if hasarch{'X86_64'}} = { # TODO extending to u32 should be trivial
  acc:DE = 0
  def {accl, _, accl_tup, accl_vec} = acc_impl{mask_ident{+,0}, +, unr, VT, SE, 0}
  def {acch, _, acch_tup, acch_vec} = acc_impl{mask_ident{+,0}, +, unr, VT, SE, 0}
  
  def __shl{a:T, b if issigned{T}} = T ~~ (ty_u{a} << b)
  
  extend perv2{__shr}
  def me{'acc', ...M, v} = match (v) {
    {v:T if primtype{T} and M{0}==0} => acc += promote{DE, v}
    {_} => {
      accl{'acc', ...M, v}
      acch{'acc', ...M, v >> 16}
    }
  }
  def me{'from_unr'} = {
    accl{'from_unr'}
    acch{'from_unr'}
  }
  def into_scal{} = {
    def ls = vfold{+, accl_vec}
    def hs = vfold{+, acch_vec}
    def ld = DE~~promote{u64, ty_u{ls} - ty_u{hs<<16}}
    def hd = promote{DE, hs}<<16
    acc+= ld + hd
  }
  def me{'to_scal', ..._} = {
    into_scal{}
  }
  def me{'flush_min'} = 65536/(unr*k)
  def me{'flush'} = {
    accl_vec = tree_fold{+, accl_tup}
    acch_vec = tree_fold{+, acch_tup}
    into_scal{}
    accl_tup = VT**0
    acch_tup = VT**0
  }
  def me{'scal_result'} = acc
  extend finish{me}
}

def assoc_accumulator{F if is{F,__min} or is{F,__max}, unr if knum{unr}, VT=([16]i8), ident if hasarch{'X86_64'} and not hasarch{'SSE4.1'}} = {
  def adda{M, a, c:([16]i8)} = mask_ident{F,ident}{M, a, ty_u{c} ^ [16]u8**128}
  def {acc, ..._} = acc_impl{adda, F, unr, [16]u8, u8, (ident%256) ^ 128}
  def me{...} = acc
  def me{'scal_result'} = i8~~(acc{'scal_result'} ^ 128)
  extend finish{me}
}

def sum_accumulator{E, unr, VT=[_]E} = assoc_accumulator{__add, unr, VT, 0}



def count_accumulator{DE, unr, VT=[k]SE if isunsigned{DE} and int_els{DE,SE}} = {
  def exact = DE==SE
  def widen_sum = SE==u8 and DE>u8
  
  def {acc, acc_scal, acc_tup, acc_vec} = acc_impl{mask_ident{add_hom_1,0}, +, unr, VT, DE, 0}
  def into_scal{vs} = {
    def curr = if (widen_sum) {
      def op{v if hasarch{'X86_64'}} = absdiff_sum{8, v, VT**0}
      def op{v if hasarch{'AARCH64'}} = {
        assert{unr*k <= 256}
        addpw{v}
      }
      cast_i{DE, vfold{+, tree_fold{+, each{op, vs}}}}
    } else {
      promote{DE, tree_fold{+, each{vfold{+,.}, vs}}}
    }
    acc_scal+= curr
  }
  
  def me{...} = acc
  def me{'acc', ...M, v} = acc{'acc', ...M, assert_hom{v}}
  def me{'from_unr'} = into_scal{slice{acc_tup, 1}}
  def me{'to_scal', ..._} = into_scal{tup{acc_vec}}
  def me{'flush_min'} = {
    if (exact) 1/0
    else if (widen_sum) maxvalue{SE}
    else __floor{maxvalue{SE}/(unr*k)}
  }
  def me{'flush'} = if (not exact) {
    into_scal{acc_tup}
    acc_tup = VT**0
  }
  extend finish{me}
}

# def count_accumulator{DE, unr, VT=[_]SE==u8 if int_els{DE,SE} and DE>SE} = { # takes 2 instrs in core loop on x86; and still needs flushing on NEON
#   def acc = sum_accumulator{u64, unr, VT}
#   def me{...} = acc
#   extend perv1{__neg}
#   def me{'acc', ...M, v} = acc{'acc', ...M, assert_hom{v}}
#   def me{'scal_result'} = cast_i{DE, acc{'scal_result'} * 0xfefefefefefefeff}
#   extend finish{me}
# }



# implicit identity values
local def of_e{[_]E, G} = G{E}
local def of_e{E if primt{E}, G} = G{E}
def assoc_accumulator{F==__min, unr, T if ktyp{T}} = assoc_accumulator{F, unr, T, of_e{T, {E} => if (isfloat{E})  E~~1/0 else maxvalue{E}}}
def assoc_accumulator{F==__max, unr, T if ktyp{T}} = assoc_accumulator{F, unr, T, of_e{T, {E} => if (isfloat{E}) -E~~1/0 else minvalue{E}}}
def assoc_accumulator{F==__add, unr, T if ktyp{T}} = assoc_accumulator{F, unr, T, 0}

def any_accumulator{unr, T} = bool_accumulator{|, unr, T, 0}
def all_accumulator{unr, T} = bool_accumulator{&, unr, T, 1}
