include 'skin/c'
include 'arch/c'
include 'util/for'
include 'util/kind'
include 'util/tup'

def ux = u64
config usz = u32
config SLOW_PDEP = 0

def same = is
oper ~~ reinterpret infix right 55
oper ** broadcast infix right 55
def extend_each{G, ...args}{...fs} = each{{f, ...args} => (if (length{args}>0) G{...args} else G){f}, fs, ...args}

def isunsigned{T} = isint{T} and not issigned{T}

def vect {T} = ktyp{T} and same{typekind{T}, 'vector'}
def primt{T} = ktyp{T} and same{typekind{T}, 'primitive'}
def any_num = match { {x:T}=>primt{T}; {x} => knum{x} }
def any_int = match { {x:T}=>isint{T};  {x} => knum{x} and (x>>0) == x }
def int_idx{_, _} = 0
def int_idx{k if knum{k}, l} = (k>>0)==k and k>=0 and k<l
def is_pow2{i if any_int{i}} = (i & (i-1)) == 0
def elwidth{T} = width{eltype{T}}

def reinterpret{T, x:T} = x
def export_tab{name, fs} = { v:*one_type{fs} = fs; export{name, v} }

oper &~ andnot infix none 35
def andnot{a, b:T if any_int{a} and primt{T}} = a & ~b
def andnot{a:T, b if primt{T} and knum{b}} = a & ~T~~b

oper &- ({v:T,m:(u1)} => v & -promote{T,m}) infix left 35

oper // ({a,b}=>__floor{a/b}) infix left 40

def ptr_add{E, ptr:P, am} = { ptr = P~~(am + *E~~ptr) }

def reverse_scan{G, v} = reverse{scan{{a,b}=>G{b,a}, reverse{v}}}

def tree_fold{F, x} = {
  def h = length{x}>>1
  assert{h>0, 'tree_fold of empty'}
  F{tree_fold{F, slice{x,0,h}}, tree_fold{F, slice{x,h,length{x}}}}
}
def tree_fold{F, {x}} = x

def eachx{F, ...args} = {
  def l = tree_fold{__max, each{{x} => if(ktup{x}) length{x} else 0, args}}
  each{F, ...each{{x} => if (ktup{x}) x else l**x, args}}
}


def load {...args if match (...args) { {ptr:*E, idx      if not vect{E}}=>0; {..._}=>1 } } = assert{0, 'bad load', ...args}
def store{...args if match (...args) { {ptr:*E, idx, val if not vect{E}}=>0; {..._}=>1 } } = assert{0, 'bad store', ...args}
def load{p:*_} = load{p, 0}
# def store{p:*_, v} = store{p, 0, v}
def loadu {p:*T      if isunsigned{T}} = emit{T,    merge{'loadu_u', fmtnat{width{T}}}, p}
def storeu{p:*T, v:T if isunsigned{T}} = emit{void, merge{'storeu_u',fmtnat{width{T}}}, p, v}
def loadu {p:*T      if issigned{T}} = loadu {*ty_u{T} ~~ p}
def storeu{p:*T, v:T if issigned{T}} = storeu{*ty_u{T} ~~ p, ty_u{v}}
def loadu {p:*T      if width{T}==8} = load{p}
def storeu{p:*T, v:T if width{T}==8} = store{p, v}



# hints
def rare{x if knum{x}} = x
def rare{x:(u1)} = emit{u1, '__builtin_expect', x, 0}
def likely{x:(u1)} = emit{u1, '__builtin_expect', x, 1}
def assert{c, ...msg} = { if (not same{c,1}) { show{...msg}; 0{} } }
def assert{0} = assert{0, 'failed assertion'}
def assert{1} = 1
def unreachable{} = emit{void, 'si_unreachable'}
def assert{x:(u1)} = { if (not x) emit{void, 'si_unreachable'} }

# various checks
def all{{...vs}} = tree_fold{&, vs}
def all{{}} = 1
def all{G, ...vs if kgen{G}} = if (all{each{{c}=>length{c}==0, vs}}) 1 else G{...each{select{.,0}, vs}} and all{G, ...each{slice{.,1}, vs}}

def one_val{{h, ...t}} = {
  each{{c} => assert{same{c,h}}, t}
  h
}
def one_val{{}} = {}
def one_type{x} = one_val{each{type, x}}
def all_same{{h, ...t}} = all{same{h,.}, t}
def all_same{{_}} = 1
def all_same{{}} = 1

def try_same_type{_, default} = default
def try_same_type{{h:T, ...t} if all{hastype{.,T}, t}, _} = T

def broadcast{n, v if knum{n}} = each{{_}=>v, range{n}}

# type stats
def minvalue{T if isunsigned{T}} = 0
def maxvalue{T if isunsigned{T}} = tail{width{T}}
def minvalue{T if issigned{T}} = - (1<<(width{T}-1))
def maxvalue{T if issigned{T}} = tail{width{T}-1}

# vector type checks (all disallow u1 element)
def genchk{W, F} = match {
  {V=[_]T   } => W{V} and F{T}
  {V=[_]T, w} => W{V} and F{T} and width{T}==w
  {..._} => 0
}
def genchks{W} = each{genchk{W,.}, tup{
  {E} =>                   E!=u1, # vece / no postfix
  {E} => isint{E}      and E!=u1, # veci
  issigned,                       # vecs
  {E} => isunsigned{E} and E!=u1, # vecu
  isfloat,                        # vecf
}}
def { w64,  w64i, w64s, w64u, w64f} = genchks{{V} => width{V} == 64}
def {w128, w128i,w128s,w128u,w128f} = genchks{{V} => width{V} == 128}
def {w256, w256i,w256s,w256u,w256f} = genchks{{V} => width{V} == 256}
def {w512, w512i,w512s,w512u,w512f} = genchks{{V} => width{V} == 512}
def {vece, veci, vecs, vecu, vecf}  = genchks{{_} => 1}

def trunc{T, x:U if isint{T} and isint{U} and width{T}<=width{U}} = emit{T, '', x}
def trunc{T, x if knum{x}} = cast{T, x}

def tern{c, T, F if any_int{c}} = if(c) T else F
def tern{c, t:T, f:T if any_int{c}} = {
  res:T = f
  if (c) res = t
  res
}

def to_w{T, w} = primtype{quality{T}, w}

def re_el{E, V} = [width{V}/width{E}]E
def re_el{E, x:V} = re_el{E,V} ~~ x

local def change_qual{q} = {
  def f{w if knum{w}} = primtype{q, w}
  def f{T if primt{T}} = primtype{q, width{T}}
  def f{V=[_]T} = re_el{f{T}, V}
  def f{x:T} = f{T}~~x
}
def ty_u = change_qual{'u'}
def ty_s = change_qual{'i'}
def ty_f = change_qual{'f'}

def w_n{T, w if primt{T}} = primtype{quality{T}, w}
def w_d{T if primt{T}} = to_w{T, width{T}*2} # double/halve primitive type width
def w_h{T if primt{T}} = to_w{T, width{T}/2}

def n_d{[k]T} = [k*2]T # double/halve vector count
def n_h{[k]T} = [k/2]T

def el_d{[k]T} = [k]w_d{T} # double/halve element width, preserving count
def el_h{[k]T} = [k]w_h{T}

def el_m{V=[_]T} = re_el{w_d{T}, V} # double/halve element width, preserving width
def el_s{V=[_]T} = re_el{w_h{T}, V}



# vector definitions
def arch_defvw{} = if (hasarch{'AVX2'}) 256 else 128
def has_simd = hasarch{'X86_64'} or hasarch{'AARCH64'}
def has_sel = hasarch{'AVX2'} or hasarch{'AARCH64'}
def fast_BMI2{} = hasarch{'BMI2'} and not SLOW_PDEP
def assert_hom{{...vs}} = each{assert_hom, vs}
def assert_hom{x:[_]E if quality{E}=='u'} = x
def sel{L=[_]_, v:[_]_, i:[_]_} = vec_shuffle{L, v, i}

# base cases
def {
  absu,and_bit_none,andn_bit_none,andnz,load_bits,blend,blend_units,clmul,cvt,extract,half,
  all_bit,any_bit,blend_bit,
  all_hom,any_hom,blend_hom,hom_to_int,store_masked_hom,store_blended_hom,
  all_top,any_top,blend_top,top_to_int,store_masked_top,store_blended_top,
  load_expand_bits,make,mask_to_hom,mulw_split,mulh,narrow,narrow_trunc,narrow_pair,
  pair,pdep,pext,bzhi,rbit,reverse_units,broadcast_sel,absdiff_sum,mul_sum,mul_sum_sat,
  unord,unzip,vfold,vec_select,vec_shuffle,widen,widen_upper,multishift,
  addp,addpw,addpwa,
}

# extended by arch/*/select where applicable
def blend_bit{f:T, t:T, m:M if width{T}==width{M}} = T ~~ ((M~~t & m) | (M~~f &~ m))
def blend_hom{f:T, t:T, m:M} = blend_bit{f, t, m}

local def anyall{is_all} = { def extend _{me} = {
  def me{...vs if length{vs}>1 and not same{try_same_type{vs,'!'},'!'}} = {
    def {a,b} = split{length{vs}/2, vs}
    me{...each{tern{is_all,&,|}, a, b}}
  }
  # def me{v:[k]E, vl if any_num{vl}} = {
  #   def {n,m:M} = hom_to_int_ext{v}
  #   if (is_all) {
  #     all:M = maxvalue{M}
  #     (m | (all << (vl*n))) == all
  #   } else {
  #     (m << (width{M} - vl*n)) != 0
  #   }
  # }
  def me{...vs, v:[k]_, k} = me{...vs, v}
}}
extend (extend_each{anyall{1}}){all_hom, all_top}
extend (extend_each{anyall{0}}){any_hom, any_top}

def hom_to_int_ext{a:T} = tup{1, hom_to_int{a}} # tup{n,mask}; mask with each bit repeated n times
def ctz_ext{{n,v}} = ctz{v}/n # ctz for a result of homMaskX
def hom_to_int{...vs if length{vs}>1} = {
  def n = length{vs}
  def [k]_ = one_type{vs}
  def RT = ty_u{__max{8,k*n}}
  def sl{...a} = promote{RT, hom_to_int{...slice{vs,...a}}}
  def h = n/2
  def lo = sl{0,h}
  def hi = sl{h}
  (hi << (h*k)) | lo
}
def hom_to_int{x if ktup{x}} = hom_to_int{...x}
def first_hom{x:[_]_} = ctz_ext{hom_to_int_ext{x}}
def popc_hom{v:(u1)} = promote{ux, v}
def popc_hom{x:[_]_} = {
  def {n,m} = hom_to_int_ext{x}
  popc{m} / n
}
def try_first_hom{x:[_]_} = {
  def ex = hom_to_int_ext{x}
  val:ux = 0
  ok:u1 = 0
  if (select{ex,1} != 0) {
    ok = 1
    val = ctz_ext{ex}
  }
  tup{val, ok}
}

def load{V=[k]E, ptr:*E   } = load{*V~~ptr, 0}
def load{V=[k]E, ptr:*E, k} = load{*V~~ptr, 0}
def store{ptr:*E, val:V=[k]E   } = store{*V~~ptr, 0, val}
def store{ptr:*E, val:V=[k]E, k} = store{*V~~ptr, 0, val}
local def extend accept_vec_ptr{op} = {
  def op{ptr:*[k]E, m:M, val:[k]E} = op{*E~~ptr, m, val}
}
extend (extend_each{accept_vec_ptr}){
  store_masked_hom,store_blended_hom,
  store_masked_top,store_blended_top,
}



if_inline (hasarch{'X86_64'}) {
  include './x86'
} else if_inline (hasarch{'AARCH64'}) {
  include 'arch/neon_intrin/basic'
  include 'arch/neon_intrin/select'
  include './neon'
  def {vec_shuffle16_lo}
} else {
  def {
    __adds,__subs,__sqrt,vec_broadcast,vec_make,
    vec_shift_left,vec_shift_left_128,
    vec_shift_right,vec_shift_right_128,
    vec_merge_shift_left,vec_merge_shift_left_128,
    vec_merge_shift_right,vec_merge_shift_right_128,
    vec_shuffle16_lo
  }
}

def mzip   {a:T, b:T, k} = el_m{T} ~~ zip   {a, b, k}
def mzip128{a:T, b:T, k} = el_m{T} ~~ zip128{a, b, k}
def pack   {a:T, b:T, k} = unzip{el_s{T}~~a, el_s{T}~~b, k}

local def extend kpair{op} = {
  def op{a:T, b:T} = tup{op{a,b,0}, op{a,b,1}}
}
extend (extend_each{kpair}){pack, zip, zip128, mzip, mzip128, unzip, unzip128}

def packs{{a, b}} = packs{a, b}
def packs128{{a, b}} = packs128{a, b}
def pair{{a, b}} = pair{a, b}

def widen{T, x:T} = x
def narrow{T, x:[_]T} = x
def undef_promote{T, x:T} = x
def zero_promote{T, x:T} = x
def cvt{T, x:[_]T} = x
def extract{V=[k]E, x:V, 0} = x
def store_narrow_relaxed{p:*DE, x:[k]E} = store{p, narrow{DE, x}, k}
def fold_addw{E, x:V=[_]E} = vfold{+, x}
def fold_addw{x:[k]E if k <= (1<<width{E})} = fold_addw{w_d{E}, x}

def broadcast{T, v if primt{T}} = v
def broadcast{V=[_]T, v} = vec_broadcast{V, if (knum{v}) v else promote{T,v}}
def make{V=[_]_, ...xs} = vec_make{V, ...xs}
def iota{V=[k]_} = make{V, ...range{k}}
def absu{a:[_]_} = ty_u{__abs{a}}
def shuf = vec_shuffle



# more arith
def __min{a, b if any_num{a} and any_num{b}} = tern{a<b, a, b}
def __max{a, b if any_num{a} and any_num{b}} = tern{a>b, a, b}
def cdiv{a,b} = (a+b-1)/b # ceiling divide
def cdiv{a,b if knum{a} and knum{b}} = __ceil{a/b}
def popc{x:T if isint{T} and width{T}==64} = emit{ux, '__builtin_popcountll', x}
def popc{x:T if isint{T} and width{T}<=32} = emit{ux, '__builtin_popcount', x}
def ctz{x:T if isint{T} and width{T}==64} = emit{ux, '__builtin_ctzll', x}
def ctz{x:T if isint{T} and width{T}<=32} = emit{ux, '__builtin_ctz', x}
def clz{x:T if isint{T} and width{T}==64} = emit{ux, '__builtin_clzll', x}
def clz{x:T if isint{T} and width{T}==32} = emit{ux, '__builtin_clz', x}
# count-leading-zeros complement, less type-dependent
def clzc{x:T if isint{T}} = width{T} - clz{x}

def ceil_log2{n} = clzc{n-1}
def ceil_log2{n if knum{n} and n>0} = ceil_log2{(n+1)>>1}+1
def ceil_log2{1} = 0

# convert tuple to number in little-endian base b
def base{b,{}} = 0
def base{b,{h,...t}} = h + b*base{b,t}

def trunc_bits{n, v if n<=8}  = cast_i{u8, v}
def trunc_bits{n, v if n==16} = cast_i{u16, v}
def trunc_bits{n, v if n==32} = cast_i{u32, v}
def trunc_bits{n, v if n==64} = cast_i{u64, v}

# base-2 log of a constant power of two
def lb{n if knum{n} and (n>>1<<1) == n and n>0} = lb{n>>1}+1
def lb{1} = 0

def tail{n} = (1<<n) - 1      # mask of the n least significant bits
def zlow{n,x} = (x >> n) << n # zero out n least significant bits
def tail{n,x} = x & tail{n}   # get the n least significant bits
def bit {k,x} = x &  (1<<k)   # get the k-th bit
def tail{R,n:N if primt{R} and primt{N}} = { assert{n<width{R}}; ((R~~1)<<n) - 1 }
def tail{R,n if primt{R} and knum{n}} = R~~((1<<n) - 1)

def bit_lut{bits, idx if length{bits}<64 and all{(bits&1) == bits}} = ((base{2,bits} >> idx) & 1) != 0

# Generalized flat transpose of iota{1<<length{bs}}
# select{tr_iota{bs}, x} sends bit i of x to position select{bs, i}
def tr_iota{...bs} = {
  def axes = each{tup{0,.}, 1<<bs}
  fold{flat_table{|,...}, reverse{axes}}
}
def tr_iota{{...bs}} = tr_iota{...bs}

# range logic
def in_range_len{x:TS=[_]T, start, count if issigned{T}} = { # ∊ [start;start+count)
  def TU = ty_u{TS}
  (TU~~(x-TS**start))  <  TU**count
}
def in_range_len{x:TU=[_]T, start, count if isunsigned{T}} = { # ∊ [start;start+count)
  def TS = ty_s{TU}
  def h = 1 << (width{T}-1)
  (TS~~(x-TU**(start-h)))  <  TS**(count-h)
}

def load{p,i if kgen{p}} = p{i}
def store{p,i,x if kgen{p}} = p{i,x}
def tptr{l,s} = { # create "pointer" generator with given load & store definitions
  def r{i} = l{i}
  def r{i,x} = s{i,x}
}

def unroll = for_const
def for_nz{vars,begin,end,iter} = {
  i:ux = begin
  assert{i!=end}
  while (i < end) {
    iter{i, vars}
    ++i
  }
}
def for_unroll_block{exp,unr}{vars,begin,end,iter} = {
  i:ux = begin
  while ((i+unr) <= end) {
    iter{each{{j}=>i+j, iota{unr}}, vars}
    i+= unr
  }
  if (unr==2) {
    if (i!=end) iter{tup{i}, vars}
  } else if (unr>1) {
    if (exp) {
      def stop = makelabel{}
      each{{j} => {
        if (i+j >= end) goto{stop}
        iter{tup{i+j}, vars}
      }, iota{unr}}
      setlabel{stop}
    } else {
      @for(j from i to end) iter{tup{j}, vars}
    }
  }
}

def for_blocks{blsz}{vars,begin,end,iter} = {
  i0:ux = begin
  i1:ux = end
  if (rare{i1>blsz}) i1 = blsz
  def el = makelabel{}
  while(1) {
    iter{tup{i0,i1}, vars}
    if (likely{i1 == end}) goto{el}
    i0 = i1
    i1 = __min{i1+blsz, ux~~end}
  }
  setlabel{el}
}
def for_blocks{0}{vars,begin,end,iter} = iter{tup{begin,end}, vars}

def make_branch{Ts, F} = {
  def args = undef{Ts}
  def skip = makelabel{}; goto{skip}
  def start = setlabel{}
  F{...args}
  setlabel{skip}
  {...vs} => { args = vs; goto{start} }
}
def make_opt_branch{enable, Ts, F} = if (enable) make_branch{Ts, F} else 'not defined'

def undef{T, n if ktyp{T}} = @collect(n) undef{T}
def undef{Ts if ktup{Ts}} = each{undef, Ts}
def undef{x:T} = undef{T}
def undef{T if ktyp{T}} = { reg:=undefined{T} }
