include 'skin/c'
include 'arch/c'
include 'util/for'
include 'util/kind'
include 'util/tup'

def ux = u64
config usz = u32
config SLOW_PDEP = 0

def same = is
oper ~~ reinterpret infix right 55
oper ** broadcast infix right 55

def isreg   = kreg
def isconst = kcon
def istype  = ktyp
def istup   = ktup

def isunsigned{T} = isint{T} and not issigned{T}

def isvec {T} = istype{T} and same{typekind{T}, 'vector'} # TODO rename these to better reflect that they apply to types
def isprim{T} = istype{T} and same{typekind{T}, 'primitive'}
def isptr {T} = istype{T} and same{typekind{T}, 'pointer'}
def elwidth{T} = width{eltype{T}}

def reinterpret{T, x:T} = x
def exportN{f, ...ns} = each{export{.,f}, ns}
def exportT{name, fs} = { v:*oneType{fs} = fs; export{name, v} }

oper &~ andnot infix none 35
def andnot{a, b:T if anyNum{a} and isprim{T}} = a & ~b
def andnot{a:T, b if isprim{T} and knum{b}} = a & ~T~~b

oper &- ({v:T,m:(u1)} => v & -promote{T,m}) infix left 35

oper // ({a,b}=>floor{a/b}) infix left 40

def ptr_add{E, ptr:P, am} = { ptr = P~~(am + *E~~ptr) }

def reverse_scan{G, v} = reverse{scan{{a,b}=>G{b,a}, reverse{v}}}

def tree_fold{F, x} = {
  def h = length{x}>>1
  assert{h>0, 'tree_fold of empty'}
  F{tree_fold{F, slice{x,0,h}}, tree_fold{F, slice{x,h,length{x}}}}
}
def tree_fold{F, {x}} = x

def eachx{F, ...args} = {
  def l = tree_fold{max, each{{x} => if(istup{x}) length{x} else 0, args}}
  each{F, ...each{{x} => if (istup{x}) x else l**x, args}}
}


def load {p:*[_]_, n   } = assert{0,'bad load',p,n}
def store{p:*[_]_, n, v} = assert{0,'bad store',p,n,v}
def load{p:*_} = load{p, 0}
# def store{p:*_, v} = store{p, 0, v}
def loadu {p:*T      if isunsigned{T}} = emit{T,    merge{'loadu_u', fmtnat{width{T}}}, p}
def storeu{p:*T, v:T if isunsigned{T}} = emit{void, merge{'storeu_u',fmtnat{width{T}}}, p, v}
def loadu {p:*T      if issigned{T}} = loadu {*ty_u{T} ~~ p}
def storeu{p:*T, v:T if issigned{T}} = storeu{*ty_u{T} ~~ p, ty_u{v}}
def loadu {p:*T      if width{T}==8} = load{p}
def storeu{p:*T, v:T if width{T}==8} = store{p, v}



# hints
def rare{x if knum{x}} = x
def rare{x:(u1)} = emit{u1, '__builtin_expect', x, 0}
def likely{x:(u1)} = emit{u1, '__builtin_expect', x, 1}
def assert{c, ...msg} = { if (not same{c,1}) { show{...msg}; 0{} } }
def assert{0} = assert{0, 'failed assertion'}
def assert{1} = 1
def unreachable{} = emit{void, 'si_unreachable'}
def assert{x:(u1)} = { if (not x) emit{void, 'si_unreachable'} }

# various checks
def all{{...vs}} = tree_fold{&, vs}
def all{{}} = 1
def all{G, ...vs if kgen{G}} = if (all{each{{c}=>length{c}==0, vs}}) 1 else G{...each{select{.,0}, vs}} and all{G, ...each{slice{.,1}, vs}}

def oneVal{{h, ...t}} = {
  each{{c} => assert{same{c,h}}, t}
  h
}
def oneVal{{}} = {}
def oneType{x} = oneVal{each{type, x}}
def allSame{{h, ...t}} = all{is{h,.}, t}
def allSame{{_}} = 1
def allSame{{}} = 1

def try_same_type{_, default} = default
def try_same_type{{h:T, ...t} if all{hastype{.,T}, t}, _} = T

def broadcast{T, v if isprim{T}} = v
def broadcast{n, v if knum{n}} = each{{_}=>v, range{n}}

# type stats
def minvalue{T if isunsigned{T}} = 0
def maxvalue{T if isunsigned{T}} = (1<<width{T})-1
def minvalue{T if issigned{T}} = - (1<<(width{T}-1))
def maxvalue{T if issigned{T}} = (1<<(width{T}-1))-1

def anyNum = match { {x:T}=>isprim{T}; {x} => knum{x} }
def anyInt = match { {x:T}=>isint{T} ; {x} => knum{x} and (x>>0) == x }

# vector width/type checks
def w64 {T} = isvec{T} and width{T}==64;  def w64 {T,w} = w64{T}  and elwidth{T}==w
def w128{T} = isvec{T} and width{T}==128; def w128{T,w} = w128{T} and elwidth{T}==w
def w256{T} = isvec{T} and width{T}==256; def w256{T,w} = w256{T} and elwidth{T}==w

# width+type checks
def genchk{B, F} = match {
  {V=[_]T   } => B{V} and F{T}
  {V=[_]T, w} => B{V} and F{T} and width{T}==w
  {..._} => 0
}
def genchks{B} = each{genchk{B,.}, tup{isint, issigned, isunsigned, isfloat}}
def { w64i, w64s, w64u, w64f} = genchks{w64}
def {w128i,w128s,w128u,w128f} = genchks{w128}
def {w256i,w256s,w256u,w256f} = genchks{w256}

def trunc{T, x:U if isint{T} and isint{U} and T<=U} = emit{T, '', x}
def trunc{T, x if knum{x}} = cast{T, x}

def tern{c, T, F if anyInt{c}} = if(c) T else F
def tern{c, t:T, f:T if anyInt{c}} = {
  res:T = f
  if (c) res = t
  res
}

def to_w{T, w} = primtype{quality{T}, w}

def re_el{E, V} = [width{V}/width{E}]E
def re_el{E, x:V} = re_el{E,V} ~~ x

local def qualChange{q} = {
  def f{w if knum{w}} = primtype{q, w}
  def f{T if isprim{T}} = primtype{q, width{T}}
  def f{V=[_]T} = re_el{f{T}, V}
  def f{x:T} = f{T}~~x
}
def ty_u = qualChange{'u'}
def ty_s = qualChange{'i'}
def ty_f = qualChange{'f'}

def w_n{T, w if isprim{T}} = primtype{quality{T}, w}
def w_d{T if isprim{T}} = to_w{T, width{T}*2} # double/halve primitive type width
def w_h{T if isprim{T}} = to_w{T, width{T}/2}

def n_d{[k]T} = [k*2]T # double/halve vector count
def n_h{[k]T} = [k/2]T

def el_d{[k]T} = [k]w_d{T} # double/halve element width, preserving count
def el_h{[k]T} = [k]w_h{T}

def el_m{V=[_]T} = re_el{w_d{T}, V} # double/halve element width, preserving width
def el_s{V=[_]T} = re_el{w_h{T}, V}



# vector definitions
def arch_defvw = if (hasarch{'AVX2'}) 256 else 128
def has_simd = hasarch{'X86_64'} or hasarch{'AARCH64'}
def has_sel = hasarch{'AVX2'} or hasarch{'AARCH64'}
def fast_BMI2{} = hasarch{'BMI2'} and not SLOW_PDEP

# test if vector has a specific width & element type
def lvec = match { {[n]T, n, (width{T})} => 1; {T, n, w} => 0 }

# base cases
def {
  absu,andAllZero,andnz,b_getBatch,blend,blend_units,clmul,cvt,extract,fold_addw,half,
  homAll,homAny,bitAll,bitAny,homMask,homMaskStore,homMaskStoreF,loadBatchBit,
  loadLow,make,maskStore,maskToHom,mulw,mulh,narrow,narrowTrunc,narrowPair,packQ,pair,pdep,
  pext,popcRand,rbit,rev,sel,shl,shr,shufInd,storeLow,
  blend_top,topMask,topMaskStore,topMaskStoreF,unord,unzip,vfold,vec_select,vec_shuffle,widen,widenUpper,
  multishift,
}

# extended by arch/*/select where applicable
def blend_bit{f:T, t:T, m:M if width{T}==width{M}} = T ~~ ((M~~t & m) | (M~~f &~ m))
def blend_hom{f:T, t:T, m:M} = blend_bit{f, t, m}

def homMaskX{a:T} = tup{1, homMask{a}} # tup{n,mask}; mask with each bit repeated n times
def ctzX{{n,v}} = ctz{v}/n # ctz for a result of homMaskX
def homMask{...vs if length{vs}>1} = {
  def n = length{vs}
  def [k]_ = oneType{vs}
  def RT = ty_u{max{8,k*n}}
  def sl{...a} = promote{RT, homMask{...slice{vs,...a}}}
  def h = n/2
  def lo = sl{0,h}
  def hi = sl{h}
  (hi << (h*k)) | lo
}
def homMask{x if ktup{x}} = homMask{...x}

if_inline (hasarch{'X86_64'}) {
  include 'arch/iintrinsic/basic'
  include 'arch/iintrinsic/select'
  include './sse2'
  include './sse'
  include './avx'
  include './avx2'
  include './avx512'
} else if_inline (hasarch{'AARCH64'}) {
  include 'arch/neon_intrin/basic'
  include 'arch/neon_intrin/select'
  include './neon'
  def {vec_shuffle16_lo}
} else {
  def {
    __adds,__subs,__sqrt,vec_broadcast,vec_make,
    vec_shift_left_128,vec_shift_right_128,vec_merge_shift_right,
    vec_shuffle16_lo
  }
}

def mzip   {a:T, b:T, k} = el_m{T} ~~ zip   {a, b, k}
def mzip128{a:T, b:T, k} = el_m{T} ~~ zip128{a, b, k}
def pack   {a:T, b:T, k} = unzip{el_s{T}~~a, el_s{T}~~b, k}

local def extend kpair{op} = {
  def op{a:T, b:T} = tup{op{a,b,0}, op{a,b,1}}
}
extend ({...f}=>each{kpair,f}){pack, zip, zip128, mzip, mzip128, unzip, unzip128}

def packQ{{a, b}} = packQ{a, b}
def pair{{a, b}} = pair{a, b}

def widen{T, x:T} = x
def narrow{T, x:[_]T} = x
def undefPromote{T, x:T} = x
def zeroPromote{T, x:T} = x
def cvt{T, x:[_]T} = x

def broadcast{V=[_]T, v} = vec_broadcast{V, promote{T,v}}
def make{V=[_]_, ...xs} = vec_make{V, ...xs}
def iota{V=[k]_} = make{V, ...iota{k}}
def absu{a:[_]_} = ty_u{abs{a}}
def shuf = vec_shuffle
def vshl = vec_merge_shift_right

def floor = __floor
def ceil = __ceil
def abs = __abs
def min = __min
def max = __max
def adds = __adds
def subs = __subs
def sqrt = __sqrt



# more arith
def min{a, b if anyNum{a} and anyNum{b}} = tern{a<b, a, b}
def max{a, b if anyNum{a} and anyNum{b}} = tern{a>b, a, b}
def cdiv{a,b} = (a+b-1)/b # ceiling divide
def cdiv{a,b if knum{a} and knum{b}} = ceil{a/b}
def popc{x:T if isint{T} and width{T}==64} = emit{ux, '__builtin_popcountll', x}
def popc{x:T if isint{T} and width{T}<=32} = emit{ux, '__builtin_popcount', x}
def ctz{x:T if isint{T} and width{T}==64} = emit{ux, '__builtin_ctzll', x}
def ctz{x:T if isint{T} and width{T}<=32} = emit{ux, '__builtin_ctz', x}
def clz{x:T if isint{T} and width{T}==64} = emit{ux, '__builtin_clzll', x}
def clz{x:T if isint{T} and width{T}==32} = emit{ux, '__builtin_clz', x}
# count-leading-zeros complement, less type-dependent
def clzc{x:T if isint{T}} = width{T} - clz{x}

def ceil_log2{n} = clzc{n-1}
def ceil_log2{n if knum{n} and n>0} = ceil_log2{(n+1)>>1}+1
def ceil_log2{1} = 0

# convert tuple to number in little-endian base b
def base{b,{}} = 0
def base{b,{h,...t}} = h + b*base{b,t}

def truncBits{n, v if n<=8}  = cast_i{u8, v}
def truncBits{n, v if n==16} = cast_i{u16, v}
def truncBits{n, v if n==32} = cast_i{u32, v}
def truncBits{n, v if n==64} = cast_i{u64, v}

# base-2 log of a constant power of two
def lb{n if knum{n} and (n>>1<<1) == n and n>0} = lb{n>>1}+1
def lb{1} = 0

def tail{n} = (1<<n) - 1      # mask of the n least significant bits
def zlow{n,x} = (x >> n) << n # zero out n least significant bits
def tail{n,x} = x & tail{n}   # get the n least significant bits
def bit {k,x} = x &  (1<<k)   # get the k-th bit

def bit_lut{bits, idx if length{bits}<64 and all{(bits&1) == bits}} = ((base{2,bits} >> idx) & 1) != 0

# Generalized flat transpose of iota{1<<length{bs}}
# select{tr_iota{bs}, x} sends bit i of x to position select{bs, i}
def tr_iota{...bs} = {
  def axes = each{tup{0,.}, 1<<bs}
  fold{flat_table{|,...}, reverse{axes}}
}
def tr_iota{{...bs}} = tr_iota{...bs}

# range logic
def inRangeLen{x:TS=[_]T, start, count if issigned{T}} = { # ∊ [start;start+count)
  def TU = ty_u{TS}
  (TU~~(x-TS**start))  <  TU**count
}
def inRangeLen{x:TU=[_]T, start, count if isunsigned{T}} = { # ∊ [start;start+count)
  def TS = ty_s{TU}
  def h = 1 << (width{T}-1)
  (TS~~(x-TU**(start-h)))  <  TS**(count-h)
}
def inRangeIncl{x:T, start, end} = inRangeLen{x, start, end-start+1} # ∊ [start;end]
def inRangeExcl{x:T, start, end} = inRangeLen{x, start, end-start} # ∊ [start;end)

# check if all tuple elements are in a given range
def inrange{t, min, max} = tree_fold{&, (t>=min) & (t<max)}
def inrange{t, s, e, min, max} = inrange{slice{t,s,e}, min, max}


def load{p,i if kgen{p}} = p{i}
def store{p,i,x if kgen{p}} = p{i,x}
def tptr{l,s} = { # create "pointer" generator with given load & store definitions
  def r{i} = l{i}
  def r{i,x} = s{i,x}
}

def unroll = for_const
def forNZ{vars,begin,end,iter} = {
  i:ux = begin
  assert{i!=end}
  while (i < end) {
    iter{i, vars}
    ++i
  }
}
def forUnroll{exp,unr}{vars,begin,end,iter} = {
  i:ux = begin
  while ((i+unr) <= end) {
    iter{each{{j}=>i+j, iota{unr}}, vars}
    i+= unr
  }
  if (unr==2) {
    if (i!=end) iter{tup{i}, vars}
  } else if (unr>1) {
    if (exp) {
      def stop = makelabel{}
      each{{j} => {
        if (i+j >= end) goto{stop}
        iter{tup{i+j}, vars}
      }, iota{unr}}
      setlabel{stop}
    } else {
      @for(j from i to end) iter{tup{j}, vars}
    }
  }
}

def for_blocks{blsz}{vars,begin,end,iter} = {
  i0:ux = begin
  i1:ux = end
  if (rare{i1>blsz}) i1 = blsz
  def el = makelabel{}
  while(1) {
    iter{tup{i0,i1}, vars}
    if (likely{i1 == end}) goto{el}
    i0 = i1
    i1 = min{i1+blsz, ux~~end}
  }
  setlabel{el}
}
def for_blocks{0}{vars,begin,end,iter} = iter{tup{begin,end}, vars}

def makeBranch{Ts, F} = {
  def args = undef{Ts}
  def skip = makelabel{}; goto{skip}
  def start = setlabel{}
  F{...args}
  setlabel{skip}
  {...vs} => { args = vs; goto{start} }
}
def makeOptBranch{enable, Ts, F} = if (enable) makeBranch{Ts, F} else 'not defined'

def undef{T, n if istype{T}} = @collect(n) undef{T}
def undef{Ts if istup{Ts}} = each{undef, Ts}
def undef{x:T} = undef{T}
def undef{T if istype{T}} = { reg:=undefined{T} }
