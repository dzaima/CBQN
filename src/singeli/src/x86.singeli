include 'arch/iintrinsic/basic'
include 'arch/iintrinsic/select'

# compact casting for the annoying intrinsic type system
def v2i{x:T=[_]E} = if(isint{E}) x else re_el{u8, x}
def v2f{x:T=[_]_} = re_el{f32, x}
def v2d{x:T=[_]_} = re_el{f64, x}
def x86_vec_low{n, E if primt{E}} = [__max{128/width{E},n}]E

def x86_has512{V=[_]E} = if (width{V}==512) hasarch{'AVX512F'} else (width{V}==256 or width{V}==128) and hasarch{'AVX512VL'}
def x86_has512{V, post} = has512{V} and hasarch{merge{'AVX512', post}}
local def has512 = x86_has512

def x86_has512e{_} = 0
def x86_has512e{V=[_]E if width{E}>=32} = has512{V}
def x86_has512e{V=[_]E if width{E}<=16} = has512{V, 'BW'}
def x86_has512e{V=[_]E, post} = x86_has512e{V} and has512{V, post}
local def hase{V=[_]E} = hase{V, 'SSE2'}
local def hase{V=[_]E, min_sse} = hase{V, min_sse, if (isint{E}) 'AVX2' else 'AVX'}
local def hase{V=[_]E, min_sse, min_avx} = hase{V, min_sse, min_avx, {} => x86_has512e{V}}
local def hase{V=[_]E, min_sse, min_avx, min_avx512} = match (width{V}) {
  {128} => hasarch{min_sse}
  {256} => hasarch{min_avx}
  {512 if kgen{min_avx512}} => min_avx512{}
  {512 if knum{min_avx512}} => min_avx512
  {512 if ksym{min_avx512}} => hasarch{min_avx512}
  {_} => 0
}

def fmtwidth{T} = fmtnat{width{T}}
local def has_bw{V} = hasarch{match (width{V}) { {128}=>'SSE2'; {256}=>'AVX2'; {512}=>'AVX512BW' }}
local def intrin{V, ...rest} = merge{'_mm', if (width{V}==128) '' else fmtwidth{V}, '_', ...rest}
def x86_intrin = intrin

local def scal_q{q, E} = match (E) {
  {(f32)} => 'ps'
  {(f64)} => 'pd'
  {_} => merge{'ep', q, fmtwidth{E}}
}
def x86_scal{E} = scal_q{quality{E}, E}

local def intrin_t{V=[_]E, ...rest} = intrin{V, ...rest, '_', scal_q{quality{E}, E}}
local def intrin_i{V=[_]E, ...rest} = intrin{V, ...rest, '_', scal_q{'i', E}}
def x86_intrin_t = intrin_t

local def vec_s{V=[_]E} = match (E) { # e.g. ps / pd / si128
  {(f32)} => 'ps'
  {(f64)} => 'pd'
  {_} => merge{'si', fmtwidth{V}}
}
local def vec_l{V=[_]E} = merge{match (E) { # e.g. ps128 / pd128 / si128
  {(f32)} => 'ps'
  {(f64)} => 'pd'
  {_} => 'si'
}, fmtwidth{V}}
local def vec_x{V=[k]E} = { # e.g. i64x2 / f32x4 / f64x2
  merge{if (isint{E}) 'i' else 'f', fmtwidth{E}, 'x', fmtnat{k}}
}
local def to_x{V=[_]E} = if (width{E}<32) re_el{i32, V} else V

include './sse'
include './avx'
include './avx2'
include './avx512'
include './bmi'



local def x86_vec_cvt{name, W, D=[_]E, x:X=[_]E} = emit{D, intrin{W, name, vec_l{X}, '_', vec_l{D}}, x}
def undef_promote{D=[kd]E, x:X=[ks]E if kd>ks} = x86_vec_cvt{'cast', D, D, x}
def  zero_promote{D=[kd]E, x:X=[ks]E if kd>ks} = x86_vec_cvt{'zext', D, D, x}

def extract{D=[kd]E, x:X=[ks]E, i if kd<ks and int_idx{i, ks/kd}} = match (width{X}, i) {
  {_, 0} => x86_vec_cvt{'cast', X, D, x}
  {256, _} => emit{D, intrin{X, 'extract', if (hasarch{'AVX2'} and isint{E}) 'i' else 'f', '128_', vec_s{X}}, x, i}
  {512, _} => {
    def Z = to_x{D}
    emit{D, intrin_i{re_el{eltype{Z},X}, 'extract', vec_x{Z}}, x, i}
  }
}
def half{x:[k]E, i} = extract{[k/2]E, x, i}

def x86_low_elts{n, x:V=[k]E} = extract{x86_vec_low{n,E}, x, 0}



# load/store
local def low_vl{vl, V=[k]_} = knum{vl} and is_pow2{vl} and vl < k and width{V}>128
def load{R=[k]E, ptr:*E,    vl if low_vl{vl, R}} = undef_promote{R, load{x86_vec_low{vl,E}, ptr, vl}}
def store{ptr:*E, x:V=[k]E, vl if low_vl{vl, V}} = store{ptr, x86_low_elts{vl, x}, vl}



# float stuff
local def avx_cmp{a:V, b:V, imm} = ty_u{emit{V, intrin_t{V, 'cmp'}, a, b, imm}}
def unord{a:V, b:V if w256f{V} and hasarch{'AVX'}} = avx_cmp{a,b,3}
def unord{a:V, b:V if w128f{V}} = ty_u{emit{V, intrin_t{V, 'cmpunord'}, a, b}}

def cvt{RE, x:V=[k]E if isfloat{RE} and vecs{V,32} and hase{V}} = {
  def RV = [k]RE
  emit{RV, intrin_t{RV, 'cvtepi32'}, x}
}


# int stuff
def any_bit{x:[_]_} = ~and_bit_none{x, x}

def mulh{a:V, b:V=[_]E if veci{V,16} and hase{V}} = emit{V, intrin_t{V, 'mulhi'}, a, b}

def  and_bit_none{x:V, y:V if width{V}<=256 and veci{V} and hase{V, 'SSE4.1'}} = emit{u1, intrin{V, 'testz_', vec_l{V}}, x, y}
def andn_bit_none{x:V, y:V if width{V}<=256 and veci{V} and hase{V, 'SSE4.1'}} = emit{u1, intrin{V, 'testc_', vec_l{V}}, y, x}

# multiplies that only read low 32 bits of arguments
def mul32{a:V, b:V=[_](u64) if hase{V          }} = emit{V, intrin_t{el_s{V}, 'mul'}, a, b}
def mul32{a:V, b:V=[_](i64) if hase{V, 'SSE4.1'}} = emit{V, intrin_t{el_s{V}, 'mul'}, a, b}

def absdiff_sum{8, a:V=[k](u8), b:V if has_bw{V}} = {
  emit{[k/8]u64, intrin{V, 'sad_epu8'}, a, b}
}
def mul_sum{2, a:V=[k](i16), b:V if has_bw{V}} = {
  emit{[k/2]i32, intrin{V, 'madd_epi16'}, a, b}
}
def mul_sum_sat{2, a:V=[k](i8), b:[k](u8) if has_bw{V}} = mul_sum_sat{2, b, a}
def mul_sum_sat{2, a:V=[k](u8), b:[k](i8) if has_bw{V}} = {
  emit{[k/2]i16, intrin{V, 'maddubs_epi16'}, a, b}
}

local def packs_impl{check}{a:V=[k]E, b:V if veci{V} and check{V} and (width{E}==16 or width{E}==32) and hase{V, if (E==u32) 'SSE4.1' else 'SSE2', 'AVX2', 'AVX512BW'}} = {
  emit{el_s{V}, intrin_i{V, 'pack', if (isunsigned{E}) 'us' else 's'}, a, b}
}
def packs128{...} = packs_impl{{_}=>1}
def packs{...} = packs_impl{{V}=>width{V}==128}

def widen{D=[k]DE, x:S=[k0]SE if isint{DE} and quality{DE}==quality{SE} and DE>SE and k<=k0 and (match (width{D}) {
  {128} => hasarch{'SSE4.1'}
  {256} => hasarch{'AVX2'}
  {512} => x86_has512e{re_el{DE,S}}
})} = {
  emit{D, intrin_i{D, 'cvtep', if (isunsigned{SE}) 'u' else 'i', fmtwidth{SE}}, x86_low_elts{k, x}}
}
